{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/aaryansingh/Non-Native Influences Investigation/Input/hi_ipa_lex.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    #split the words in each line by 1st space\n",
    "    with open('phonemes_hindi.txt', 'w') as f:\n",
    "        for line in lines:\n",
    "            words = line.split(' ', 1)\n",
    "            #remove all newlines from word[1]\n",
    "            words[1] = words[1].replace('\\n', '')\n",
    "            #add words[1] to a new file with name phonemes_telugu.txt\n",
    "                #if word[1] first character is a space then remove it\n",
    "            if words[1][0] == ' ':\n",
    "                f.write(words[1][1:] + '\\n')\n",
    "            else:\n",
    "                f.write(words[1] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'ii', 'y', 'N', 'k', 'dxq', 't', 'aa', 'uu', 'b', 'r', 'sh', 'ee', 'nx', 'l', 'c', 'w', 's', 'm', 'u', 'tx', 'i', 'o', 'kh', 'sx', 'g', 'n', 'jq', 'j', 'p', 'ch', 'h', 'txh', 'mq', 'dx', 'hq', 'th', 'rq', 'd', 'bh', 'dh', 'ax', 'ou', 'ae', 'ph', 'lx', 'ei', 'jh', 'dxh', 'gh', 'nj', 'khq', 'phq', 'ai', 'rrq', 'au', 'kq', 'dxhq', 'gq', 'sq']\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "# from the file phonemes_tamil.txt, give me a list of all unique phonemes\n",
    "# ignore newline characters\n",
    "\n",
    "with open('phonemes_hindi.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    phonemes = []\n",
    "    for line in lines:\n",
    "        line = line.replace('\\n', '')\n",
    "        for phoneme in line.split(' '):\n",
    "            if phoneme not in phonemes:\n",
    "                phonemes.append(phoneme)\n",
    "    print(phonemes)\n",
    "    print(len(phonemes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary with keys and values\n",
    "ipa_to_arpa = {'a':'AH', 'n':'N', 'nz':'N', 'nx':'N', 'ii':'IH', 's':'S', 'l':'L', 'lx':'L', 't':'T', 'tx':'T', 'r':'R', 'rx':'R', 'k':'K', 'c':'K', 'i':'IY', 'd':'D', 'dx':'D', 'm':'M', 'j':'Z', 'e':'EH', 'aa':'AA', 'b':'B', 'p':'P', 'o':'OW', 'phq':'F', 'ee':'EY', 'g':'G', 'ai':'AY', 'ng':'NG', 'nj':'NG', 'u':'UW', 'h':'HH', 'hq':'HH', 'w':'W', 'sh':'SH', 'sx':'SH', 'y':'Y', 'au':'AW', 'oo':'AW', 'uu':'UH', 'zh':'ZH', 'N':'N', 'dxq':'R', 'kh':'K_HH', 'jq':'ZH', 'ch':'CH', 'txh':'T_TH', 'mq':'N', 'th':'TH', 'rq':'R', 'bh':'B_HH', 'dh':'DH', 'ax':'AO', 'ou':'AO', 'ae':'AE', 'ph':'F', 'ei':'AE', 'jh':'ZH', 'dxh':'D_DH', 'gh':'G_HH', 'khq':'K_HH', 'rrq':'R_IH', 'kq':'K', 'dxhq':'D_DH', 'gq':'G', 'sq':'S', 'v':'V', ':':'','uhq':'UX', 'njh':'N_JH'}\n",
    "arpa_phonemes = ipa_to_arpa.values()\n",
    "# change all the keys to values in phonemes_tamil.txt\n",
    "with open('phonemes_hindi.txt', 'w') as f:\n",
    "    for key in ipa_to_arpa:\n",
    "        f.write(ipa_to_arpa[key])\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [arpa_phonemes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AH', 'K', 'R', 'UH']\n"
     ]
    }
   ],
   "source": [
    "arpa_phoneme_list = []\n",
    "# create a new file tamil_arpa.txt\n",
    "with open('hi_arpa_lex.txt', 'w') as arpa, open('/Users/aaryansingh/Non-Native Influences Investigation/Input/hi_ipa_lex.txt','r') as ipa :\n",
    "    ipa_lines = ipa.readlines()\n",
    "    for line in ipa_lines:\n",
    "        phoneme_seq = line.split(' ', 1)\n",
    "        #remove all newlines from word[1] and leading and trailing spaces\n",
    "        phoneme_seq[1] = phoneme_seq[1].replace('\\n', '')\n",
    "        phoneme_seq[1] = phoneme_seq[1].strip()\n",
    "\n",
    "\n",
    "        phonemes = phoneme_seq[1].split(' ')\n",
    "    \n",
    "        # conver to arpa using new_dict else use\n",
    "        arpa_phonemes = []\n",
    "        for phoneme in phonemes:\n",
    "            if phoneme in ipa_to_arpa:\n",
    "                arpa_phonemes.append(ipa_to_arpa[phoneme])\n",
    "            else:\n",
    "                arpa_phonemes.append('N/A')\n",
    "        # print(arpa_phonemes)\n",
    "        arpa_phoneme_list.append(arpa_phonemes)\n",
    "        #write to tamil_arpa.txt\n",
    "        arpa.write(phoneme_seq[0] + ' ')\n",
    "        for arpa_phoneme in arpa_phonemes:\n",
    "            arpa.write(arpa_phoneme + ' ')\n",
    "        arpa.write('\\n')\n",
    "\n",
    "print(arpa_phoneme_list[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed.\n",
      "Word2Vec<vocab=45, vector_size=20, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for the Word2Vec model\n",
    "vector_size = 20\n",
    "window = 3\n",
    "min_count = 1\n",
    "epochs = 1000  # Initial number of epochs\n",
    "\n",
    "# Initialize and build the model\n",
    "model = Word2Vec(vector_size=vector_size, window=window, min_count=min_count, workers=4)\n",
    "model.build_vocab(vocab)\n",
    "\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Training loop to ensure training runs for at least 5-7 minutes\n",
    "max_time = 3xs * 60  # 7 minutes in seconds\n",
    "epoch_increment = 100  # Number of epochs to train in each iteration\n",
    "\n",
    "while True:\n",
    "    model.train(arpa_phoneme_list, total_examples=model.corpus_count, epochs=epoch_increment)\n",
    "    \n",
    "    # Check elapsed time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    if elapsed_time >= max_time:\n",
    "        break\n",
    "\n",
    "print(\"Training completed.\")\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N': 0, 'R': 1, 'K': 2, 'ZH': 3, 'K_HH': 4, 'G': 5, 'NG': 6, 'HH': 7, 'SH': 8, 'AW': 9, 'D': 10, 'F': 11, 'T': 12, 'AO': 13, 'AE': 14, 'D_DH': 15, 'L': 16, 'S': 17, 'IY': 18, 'OW': 19, 'M': 20, 'Z': 21, 'EH': 22, 'AA': 23, 'B': 24, 'IH': 25, 'P': 26, 'N_JH': 27, 'UW': 28, 'EY': 29, 'AY': 30, 'UX': 31, 'W': 32, 'Y': 33, 'UH': 34, 'CH': 35, 'T_TH': 36, 'TH': 37, 'B_HH': 38, 'DH': 39, 'G_HH': 40, 'R_IH': 41, 'V': 42, '': 43, 'AH': 44}\n"
     ]
    }
   ],
   "source": [
    "# print model vocab\n",
    "print(model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AA', 0.6833361983299255), ('IH', 0.6347345113754272), ('UW', 0.5870162844657898), ('IY', 0.5170732140541077), ('UH', 0.4785149097442627), ('EY', 0.4503912627696991), ('OW', 0.3194523751735687), ('NG', 0.24239709973335266), ('ZH', 0.17238597571849823), ('', 0.15280021727085114)]\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "print(model.wv.most_similar('AH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model with name tamil_word2vec and current date\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "model.save('hindi_word2vec_.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
